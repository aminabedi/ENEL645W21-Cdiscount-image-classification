{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a90a8sE_abWS"
   },
   "source": [
    "# Project - Cdiscount Image Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQSDw9jO3VP9"
   },
   "source": [
    "# Data ingestion\n",
    "The primary training set is a 57GB bson file, having ~15 Million images (180x180 images in Base64 format) of ~7.06 Million products. We have imported the dataset into a MongoDB instance on a VPS, so we were able to query among the records.\n",
    "We have chosen 100 categories, which overally consist of ~246K images of ~110K products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NunsFV4jxHc"
   },
   "source": [
    "## Dataset preparation\n",
    "\n",
    "First we need to ensure that the \"gdown\" library is installed and accessible in the environment and download the train_medium data from Google Drive,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sVPqZO_a0mc5",
    "outputId": "23317fca-244e-499b-9ff9-be89855d8198"
   },
   "outputs": [],
   "source": [
    "! pip install gdown && gdown --id 1F6Xf4yiYxeFEN6qhrL3YBNs0Vhx0bXJ1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note for the team\n",
    "Since the original dataset is pretty large, I've created a subset file containing ~250K photos in 100 categories, but it is still so large that it may not fit into the memory, so I've used the below parameters to load a fitable subset accordingly, please read the comments of each variable careflully, and do not change the loading code please, just the values of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVERT_TO_NP_ARRAY= False   # Wether convert the Base64 string to (180,180,3) arrays or keep the string.\n",
    "REPLACE_BASE64_SPECIAL_CHARS = True\n",
    "\n",
    "LOADING_MODE = \"all\" \n",
    "                             # num_records: Loads the first NUM_RECORDS in the dataset and calculates NUM_CATEGORIES dynamically\n",
    "                             # num_categories: Loads first NUM_CATEGORIES and calculates NUM_RECORDS dynamically\n",
    "                             # all: Loads all the 250K images, ignores all parameters below\n",
    "                            \n",
    "    \n",
    "NUM_RECORDS = 3000           # Only used when the mode is set to num_records\n",
    "NUM_CATEGORIES = 10           # Only used when the mode is set to num_category\n",
    "MAX_RECORDS_PER_CATEGORY = 0 # if not zero, will ensure that there is no more per category in the dataframe, won't work when mode is set to all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num records: 3000\n",
      "Num categories: 99\n",
      "Training df shape: (246261, 4)\n",
      "Mem used by images: 1613 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import base64\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "FILE_NAME= \"train_shuffled_100cat.csv\"\n",
    "header = 3\n",
    "\n",
    "df = pd.read_csv(FILE_NAME, header=3, nrows=0)\n",
    "\n",
    "if LOADING_MODE == \"all\":\n",
    "    df = pd.read_csv(FILE_NAME, header=header)\n",
    "\n",
    "if LOADING_MODE == \"num_records\":\n",
    "    reader = pd.read_csv(FILE_NAME, header=header, chunksize=min(NUM_RECORDS, 100))\n",
    "    for chunk in reader:\n",
    "        df = df.append(chunk, ignore_index=True)\n",
    "        if MAX_RECORDS_PER_CATEGORY:\n",
    "            for cat in df[\"category_id\"].unique():\n",
    "                if len(df[df[\"category_id\"] == cat]) > MAX_RECORDS_PER_CATEGORY:\n",
    "                    removed_rows = df[df[\"category_id\"] == cat][MAX_RECORDS_PER_CATEGORY:]\n",
    "                    df = df.drop(removed_rows.index)\n",
    "        if df.shape[0]>=NUM_RECORDS:\n",
    "            df = df.head(NUM_RECORDS)\n",
    "            break\n",
    "    \n",
    "elif LOADING_MODE == \"num_categories\": \n",
    "    reader = pd.read_csv(FILE_NAME, header=header, chunksize=100)\n",
    "    for chunk in reader:\n",
    "        df = df.append(chunk, ignore_index=True)\n",
    "        if df[\"category_id\"].nunique() > NUM_CATEGORIES:\n",
    "            break\n",
    "    if MAX_RECORDS_PER_CATEGORY:\n",
    "        for cat in df[\"category_id\"].unique():\n",
    "            if len(df[df[\"category_id\"] == cat]) > MAX_RECORDS_PER_CATEGORY:\n",
    "                removed_rows = df[df[\"category_id\"] == cat][MAX_RECORDS_PER_CATEGORY:]\n",
    "                df = df.drop(removed_rows.index)\n",
    "\n",
    "    cat_removed = df[\"category_id\"].unique()[NUM_CATEGORIES:]\n",
    "    df = df.loc[~df['category_id'].isin(cat_removed)]\n",
    "    NUM_RECORDS= df.shape[0]\n",
    "\n",
    "if CONVERT_TO_NP_ARRAY:        \n",
    "    df[\"image\"] = df[\"image\"].apply(\n",
    "                    lambda x: np.array(Image.open(io.BytesIO(base64.b64decode(x)))).reshape(180,180,3)\n",
    "                )\n",
    "if REPLACE_BASE64_SPECIAL_CHARS:\n",
    "    df[\"image\"] = df[\"image\"].apply(\n",
    "                    lambda x: x.replace('/', '_').replace('+', '-')\n",
    "                )\n",
    "    \n",
    "NUM_CATEGORIES = df['category_id'].nunique()\n",
    "\n",
    "categories = df['category_id'].unique()\n",
    "categories.sort()\n",
    "category_id_map = {k: v for v, k in enumerate(categories)}\n",
    "df[\"class\"] = df[\"category_id\"].apply(lambda x: category_id_map[x])\n",
    "\n",
    "print(\"Num records:\", NUM_RECORDS)\n",
    "print(\"Num categories:\", NUM_CATEGORIES)\n",
    "print(\"Training df shape:\", df.shape)\n",
    "print(\"Mem used by images:\", int(sum(df[\"image\"].apply(lambda x: x.nbytes if type(x)!=str else len(x))/10 ** 6)), \"MB\")\n",
    "# print(len(df.at[0, \"image\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "import matplotlib.pyplot as plt\n",
    "if CONVERT_TO_NP_ARRAY:\n",
    "    for index, item in df.head(10).iterrows():\n",
    "        plt.subplot(2, 5, index+1)\n",
    "        plt.title(item[2])\n",
    "        plt.imshow(item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT: For training small dataset you can skip this part of code\n",
    "## Chunk reader higher level function\n",
    "Below I've defined a function which you can call with another function as input, it will call the input function as many times with chunks of the dataset till the whole dataset is passed to it.\n",
    "### Note: In the input function, you shouldn't store the passed chunks in a global variable, or your program will crash due to a memory congestion.\n",
    "Remember, each image is a 180x180x3 3D np.array object, so the size of each record is ~97KB, therefore the size of the dataset when converted to np.array object equals ~24 GB which will not fit into your memory nor in the colab associated memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "HyJKcfvcluOZ",
    "outputId": "0cffb024-d1cc-4b57-ea6f-09d029676414",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_func_by_chunks(func, chunk_size=10 ** 4, num_runs=-1):\n",
    "    chunk_num=0\n",
    "    rets = ()\n",
    "    with pd.read_csv(\"train_shuffled_100cat.csv\", header=3, chunksize=chunk_size) as reader:\n",
    "        for chunk in reader:\n",
    "            \n",
    "            chunk[\"image\"] = chunk[\"image\"].apply(\n",
    "                lambda x: np.array(Image.open(io.BytesIO(base64.b64decode(x)))).reshape(180,180,3)\n",
    "            )\n",
    "            \n",
    "            rets+=(func(np.array(chunk), chunk_num),)\n",
    "            if num_runs==chunk_num+1:\n",
    "                return rets\n",
    "            chunk_num+=1\n",
    "    return rets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_chunks_and_sum_size(ch, ch_num):\n",
    "    print(\"*\", ch_num, \":\", ch[0,1].shape)\n",
    "    return ch.shape[0]\n",
    "x = run_func_by_chunks(log_chunks_and_sum_size, chunk_size=1000, num_runs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9gg39dI6f-E"
   },
   "source": [
    "## 1. Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W94KecGabAoB",
    "outputId": "6859da90-eede-43a0-8b35-5ff33cb2a1a0"
   },
   "outputs": [],
   "source": [
    "print(df[\"image\"].nbytes)\n",
    "X_dev = np.stack(df[\"image\"]) if CONVERT_TO_NP_ARRAY else np.array(df[\"image\"])\n",
    "Y_dev = np.array(df[\"class\"])\n",
    "print(X_dev.shape,Y_dev.shape, Y_dev[-10:])\n",
    "print(X_dev[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0KQWQTcbjUx"
   },
   "source": [
    "## 2. Explore your data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSVj9Xm2_Qsl"
   },
   "source": [
    "Showing 10 samples from dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "xxMSDDkB6f-G",
    "outputId": "e7c03f86-55d5-44c0-e646-05e4e9aa25a3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6), dpi=1000)\n",
    "indexes = np.arange(len(X_dev))\n",
    "np.random.shuffle(indexes)\n",
    "if CONVERT_TO_NP_ARRAY:\n",
    "    for idx in range(10):\n",
    "      plt.subplot(2, 5, idx + 1)\n",
    "      plt.imshow(X_dev[indexes[idx]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hExX4dqr_XNZ"
   },
   "source": [
    "#Splitting dev set into train/val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fv6OSGIO_bfG",
    "outputId": "a5042e1c-e82d-4654-8c8e-f494b0f9517d"
   },
   "outputs": [],
   "source": [
    "num_train = int(len(X_dev) * .7) #= splitting point of train/val set\n",
    "num_val = int(len(X_dev) * .2)\n",
    "num_test = len(X_dev) - num_train - num_val\n",
    "\n",
    "X_train = X_dev[indexes[:num_train]]\n",
    "Y_train = Y_dev[indexes[:num_train]]\n",
    "\n",
    "X_val = X_dev[indexes[num_train:-num_test]]\n",
    "Y_val = Y_dev[indexes[num_train:-num_test]]\n",
    "\n",
    "X_test = X_dev[indexes[-num_test:]]\n",
    "Y_test = Y_dev[indexes[-num_test:]]\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sswDlu56f-H"
   },
   "source": [
    "## 3. Represent your labels using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbQ9b9TA6f-I",
    "outputId": "77d2cb47-d639-4d8d-eaf3-93ae9163177b"
   },
   "outputs": [],
   "source": [
    "Y_train_oh = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_val_oh = tf.keras.utils.to_categorical(Y_val)\n",
    "Y_test_oh = tf.keras.utils.to_categorical(Y_test)\n",
    "\n",
    "\n",
    "print(\"Y_train\",  Y_train[:3])\n",
    "print(\"Y_train_oh:\",  Y_train_oh[:3])\n",
    "print(\"Y_val\",  Y_val[:3])\n",
    "print(\"Y_val_oh:\",  Y_val_oh[:3])\n",
    "print(\"Y_test\",  Y_test[:3])\n",
    "print(\"Y_test_oh:\",  Y_test_oh[:3])\n",
    "\n",
    "\n",
    "#Scaling outputs\n",
    "X_train_sc = X_train\n",
    "X_val_sc = X_val\n",
    "X_test_sc = X_test\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfQzijUy6f-J"
   },
   "source": [
    "## 4. Data scaling and Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "iPiPafry6f-L",
    "outputId": "a464860b-0034-4531-c5a0-dd0316378ed6"
   },
   "outputs": [],
   "source": [
    "# Experiment with different data scaling methods\n",
    "\n",
    "scaling_mode = 2  #= 0: disabled, 1: min-max normalization, 2: standardization\n",
    "\n",
    "X_train = X_train_sc \n",
    "X_val = X_val_sc \n",
    "X_test = X_test_sc \n",
    "\n",
    "if scaling_mode == 1: \n",
    "  x_train_min = X_train.min()\n",
    "  x_train_max = X_train.max()\n",
    "  X_train = ( X_train - x_train_min ) / (x_train_max - x_train_min)\n",
    "  x_val_min = X_val.min()\n",
    "  x_val_max = X_val.max()\n",
    "  X_val = ( X_val - x_val_min ) / (x_val_max - x_val_min)\n",
    "  x_test_min = X_test.min()\n",
    "  x_test_max = X_test.max()\n",
    "  X_test = ( X_test - x_test_min ) / (x_test_max - x_test_min)\n",
    "elif scaling_mode == 2:\n",
    "  x_train_mean = X_train.mean()\n",
    "  x_train_std = X_train.std()\n",
    "#   print(x_train_mean, x_train_std)\n",
    "  X_train = ( X_train - x_train_mean ) / x_train_std\n",
    "  X_val = ( X_val - x_train_mean ) / x_train_std\n",
    "  X_test = ( X_test - x_train_mean ) / x_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eUOC5D_0ajv"
   },
   "outputs": [],
   "source": [
    "# Create your data augmentation object to improve training\n",
    "# set your batch size\n",
    "\n",
    "batch_size = 32\n",
    "gen_params = {\"featurewise_center\":False,\"samplewise_center\":False,\"featurewise_std_normalization\":False,\\\n",
    "              \"samplewise_std_normalization\":False,\"zca_whitening\":False,\"rotation_range\":50,\"width_shift_range\":0.1,\"height_shift_range\":0.1,\\\n",
    "              \"shear_range\":0.1, \"zoom_range\":0.1,\"horizontal_flip\":True,\"fill_mode\":'nearest',\\\n",
    "               \"cval\": 0}\n",
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(**gen_params)\n",
    "val_gen = tf.keras.preprocessing.image.ImageDataGenerator(**gen_params)\n",
    "\n",
    "train_gen.fit(X_train,seed = 1)\n",
    "val_gen.fit(X_val, seed = 1)\n",
    "\n",
    "train_flow = train_gen.flow(X_train,Y_train_oh,batch_size = batch_size)\n",
    "val_flow = val_gen.flow(X_val,Y_val_oh,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "8j0mlSc9boRp",
    "outputId": "df5a11bd-8319-4247-bff8-d0bea3e5ebd5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6), dpi=1000)\n",
    "Xbatch,Ybatch = train_flow.__getitem__(1)\n",
    "Xbatch_min = Xbatch.min(axis=1, keepdims=True)\n",
    "Xbatch_max = Xbatch.max(axis=1, keepdims=True)\n",
    "\n",
    "for ii in range(min(10, batch_size)):\n",
    "    plt.subplot(2,5,ii+1)\n",
    "    plt.imshow(Xbatch[ii].reshape(180, 180, 3), cmap=plt.get_cmap('gray'))\n",
    "               \n",
    "               \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "def preprocess_and_decode(img_str, new_shape=(180,180)):\n",
    "#         img_str = img_str.replace('/', '_').replace('+', '-')\n",
    "        img = tf.io.decode_base64(img_str)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, new_shape, method=tf.image.ResizeMethod.BILINEAR)\n",
    "        return img\n",
    "InputLayer = tf.keras.layers.Input(shape = (1,),dtype=\"string\")\n",
    "OutputLayer = tf.keras.layers.Lambda(lambda img : tf.map_fn(lambda im : preprocess_and_decode(im[0]), img, dtype=\"float32\"))(InputLayer)\n",
    "base64_model = tf.keras.Model(InputLayer,OutputLayer)  \n",
    "\n",
    "print(preprocess_and_decode(X_dev[0]))\n",
    "# print(len(X_dev[0]),len(base64.b64decode(X_dev[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SbUTvdj6f-S"
   },
   "source": [
    "## Convolutional Model\n",
    "\n",
    "## 5. Define your  model, cost function, optimizer, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SycQoiF96f-S"
   },
   "outputs": [],
   "source": [
    "# Define your model here. Include accuracy in the metrics list when you compile it\n",
    "# Experiment with different network architectures, learnig rates, dropout, etc.\n",
    "def my_model_cnn(ishape = (180,180,3), k = NUM_CATEGORIES, lr = 1e-3):\n",
    "    input64 = tf.keras.layers.Input(shape=(1,), dtype=\"string\")\n",
    "    img_tensor = tf.keras.layers.Lambda(\n",
    "        lambda img: tf.map_fn(lambda im: preprocess_and_decode(im[0]), img, dtype=\"float32\"))(input64)\n",
    "#     model_input = tf.keras.layers.Input(shape= ishape)\n",
    "    l1 = tf.keras.layers.Conv2D(192, (3,3), padding = 'same', activation= 'relu')(img_tensor)\n",
    "    l2 = tf.keras.layers.Conv2D(192, (3,3), padding = 'same', activation= 'relu')(l1)\n",
    "    l2_drop = tf.keras.layers.Dropout(0.25)(l2)\n",
    "    l3 = tf.keras.layers.MaxPool2D((2,2))(l2_drop)\n",
    "    l4 = tf.keras.layers.Conv2D(384, (3,3), padding = 'same', activation='relu')(l3)\n",
    "    l5 = tf.keras.layers.Conv2D(384, (3,3), padding = 'same', activation='relu')(l4)\n",
    "    l5_drop = tf.keras.layers.Dropout(0.25)(l5)\n",
    "    l6 = tf.keras.layers.MaxPool2D((2,2))(l5_drop)\n",
    "    flat = tf.keras.layers.Flatten()(l6)\n",
    "    out = tf.keras.layers.Dense(k, activation= 'softmax')(flat)\n",
    "    model = tf.keras.models.Model(inputs = input64, outputs = out)\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr), loss = 'categorical_crossentropy', metrics= [\"accuracy\"])\n",
    "    return model\n",
    "model = my_model_cnn()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHNJ0kTU6f-S"
   },
   "source": [
    "## 6. Define your callbacks (save your model, patience, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUMIu1AU6f-T"
   },
   "outputs": [],
   "source": [
    "model_name_cnn = \"cdiscount_CCN.h5\"\n",
    "\n",
    "# define your callbacks\n",
    "# remember that you need to save the weights of your best model!\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 20)\n",
    "\n",
    "monitor = tf.keras.callbacks.ModelCheckpoint(model_name_cnn, monitor='val_loss',\\\n",
    "                                             verbose=0,save_best_only=True,\\\n",
    "                                             save_weights_only=True,\\\n",
    "                                             mode='min')\n",
    "# Learning rate schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch%10 == 0:\n",
    "        lr = lr/2\n",
    "    return lr\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTf4Ia126f-T"
   },
   "source": [
    "## 7. Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5L1L1y1W6f-T"
   },
   "outputs": [],
   "source": [
    "# train your model - decide for how many epochs\n",
    "model.fit(X_train,Y_train_oh,batch_size = 32, epochs = 150, \\\n",
    "          verbose = 1, callbacks= [early_stop, monitor, lr_schedule],validation_data=(X_val,Y_val_oh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1dlyCsu6f-U"
   },
   "source": [
    "## 8. Test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ernzhme6f-U"
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_name_cnn)\n",
    "metrics = model.evaluate(X_test,Y_test_oh)\n",
    "\n",
    "Ypred = model.predict(X_test).argmax(axis = 1)\n",
    "wrong_indexes = np.where(Ypred != Y_test)[0]\n",
    "print(wrong_indexes.size)\n",
    "\n",
    "# Disaplying some samples from the development set\n",
    "sample_indexes = np.random.choice(np.arange(wrong_indexes.shape[0], dtype = int),size = 30, replace = False)\n",
    "plt.figure(figsize = (24,18))\n",
    "for (ii,jj) in enumerate(sample_indexes):\n",
    "    plt.subplot(5,6,ii+1)\n",
    "    plt.imshow(X_test[wrong_indexes[jj]], cmap = \"gray\")\n",
    "    plt.title(\"Label: %d, predicted: %d\" %(Y_test[wrong_indexes[jj]],Ypred[wrong_indexes[jj]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1zHR2k76f-V"
   },
   "source": [
    "##  Team members participtaion\n",
    "(include the description of what each team member did and the consensus score for each team member)\n",
    "\n",
    "- **Arya Stark** helped design the model and write the code for fully connected model (**score 3**)\n",
    "- **Luke Skywalker** helped design helped to implement the data augmentation module (**score 3**)\n",
    "- ..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "assignment02.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
